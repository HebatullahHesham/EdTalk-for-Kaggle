{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Clone Repo:**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!git clone https://github.com/zachysaur/EDTalk.git\n","%cd EDTalk"]},{"cell_type":"markdown","metadata":{},"source":["# **Install Requirements:**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install torch==1.13.0 torchvision==0.14.0\n","!apt-get install -y ffmpeg\n","!ffmpeg -version"]},{"cell_type":"markdown","metadata":{},"source":["# **Install Checkpoints:**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%cd /kaggle/working/EDTalk\n","!rm -rf ckpts\n","!git clone https://huggingface.co/tanshuai0219/EDTalk ckpts\n","!ls /kaggle/working/EDTalk/ckpts\n","!mv /kaggle/working/EDTalk/ckpts/ckpts/* /kaggle/working/EDTalk/ckpts/\n","!rm -rf /kaggle/working/EDTalk/ckpts/ckpts"]},{"cell_type":"markdown","metadata":{},"source":["# **Enable Face Super-resolution:**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install facexlib\n","!pip install tb-nightly -i https://mirrors.aliyun.com/pypi/simple\n","!pip install gfpgan"]},{"cell_type":"markdown","metadata":{},"source":["# **Option (1) Generate with Super-resolution:**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python demo_lip_pose.py --fix_pose --source_path path/to/image.png --audio_driving_path path/to/audio.mp3 --pose_driving_path path/to/pose --save_path .mp4 --face_sr"]},{"cell_type":"markdown","metadata":{},"source":["# **Option (2) Generate with Default:**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python demo_lip_pose.py --fix_pose --source_path path/to/image --audio_driving_path path/to/audio --save_path path/to/save"]},{"cell_type":"markdown","metadata":{},"source":["# **Option (3) Generate with expressions:**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python demo_EDTalk_A_using_predefined_exp_weights.py --source_path path/to/image --audio_driving_path path/to/audio --pose_driving_path path/to/pose --exp_type type/of/expression --save_path path/to/save"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5961193,"sourceId":9739230,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
